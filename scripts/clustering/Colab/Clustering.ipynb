{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "IMPORTANT:\n",
        "This project is designed to run exclusively on Google Colab.\n",
        "\n",
        "It relies on Google Drive being mounted at:\n",
        "    /content/drive/MyDrive/\n",
        "\n",
        "Local execution is not supported.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "KEbJTGjO5TDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INSTALLING LIBRARIES**"
      ],
      "metadata": {
        "id": "3fVjvD9oNBzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install igraph faiss-cpu leidenalg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh7gsBVKI54F",
        "outputId": "52d23aab-1f25-463c-ede1-8ee96597bba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting igraph\n",
            "  Downloading igraph-0.11.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting leidenalg\n",
            "  Downloading leidenalg-0.10.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting texttable>=1.6.2 (from igraph)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading igraph-0.11.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading leidenalg-0.10.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable, igraph, faiss-cpu, leidenalg\n",
            "Successfully installed faiss-cpu-1.12.0 igraph-0.11.9 leidenalg-0.10.2 texttable-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MOUNTS DRIVE**"
      ],
      "metadata": {
        "id": "Jq50VKecH_Pm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGRGIh1vH7TQ",
        "outputId": "530fff92-352b-46f3-c3e6-7fff414c0fd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Trabalhos/TJ/NeuroScape\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # Mounts Google Drive into the Colab environment to access project files\n",
        "\n",
        "# Changes the current working directory to the NeuroScape project folder in Google Drive\n",
        "%cd /content/drive/MyDrive/NeuroScape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTING LIBRARIES**"
      ],
      "metadata": {
        "id": "JHxzeWQ7IDAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import igraph as ig\n",
        "import psutil\n",
        "import sys\n",
        "import leidenalg\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import deque\n",
        "from glob import glob\n",
        "from src.utils.clustering import *\n",
        "from src.utils.parsing import parse_directories\n",
        "\n",
        "from src.utils.load_and_save import load_embedding_shards\n",
        "from dotenv import load_dotenv, find_dotenv"
      ],
      "metadata": {
        "id": "LnGju0S7IDav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph construction**"
      ],
      "metadata": {
        "id": "aYSJR1--IJwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.utils.clustering import *\n",
        "from src.utils.parsing import parse_directories\n",
        "\n",
        "from src.utils.load_and_save import load_embedding_shards\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/NeuroScape/src')\n",
        "\n",
        "load_dotenv(\"/content/drive/MyDrive/NeuroScape/keys.env\")\n",
        "BASEPATH = os.environ['BASEPATH']\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    configurations = load_configurations()['graph_construction']\n",
        "    directories = parse_directories()\n",
        "\n",
        "    shard_directory = os.path.join(\n",
        "        BASEPATH, directories['internal']['intermediate']['hdf5']['neuro'])\n",
        "    graph_directory = os.path.join(\n",
        "        BASEPATH, directories['internal']['intermediate']['graphs'])\n",
        "\n",
        "    files = glob(os.path.join(shard_directory, '*.h5'))\n",
        "    graph_file = os.path.join(graph_directory, 'article_similarity.graphml')\n",
        "\n",
        "    print('Loading embeddings...')\n",
        "    embeddings, pmids = load_embedding_shards(files)\n",
        "\n",
        "    num_points = embeddings.shape[0]\n",
        "    num_neighbors = configurations['num_neighbors']\n",
        "    available_memory_gb = psutil.virtual_memory().available / (1024**3)\n",
        "\n",
        "    # Check if the selected k will fit into memory\n",
        "    if not check_memory_constraints(num_points, num_neighbors,\n",
        "                                    available_memory_gb):\n",
        "        raise MemoryError(\n",
        "            \"Not enough memory for the selected k. Please reduce k or upgrade your hardware.\"\n",
        "        )\n",
        "\n",
        "    print('Constructing k-NN graph...')\n",
        "    edges, weights = construct_knn_graph(embeddings, num_neighbors)\n",
        "\n",
        "    print('Creating igraph Graph object...')\n",
        "    G = ig.Graph(edges=edges, directed=False)\n",
        "    G.vs['pmid'] = pmids\n",
        "    G.es['weight'] = weights\n",
        "\n",
        "    print('Saving graph...')\n",
        "    os.makedirs(os.path.dirname(graph_file), exist_ok=True)\n",
        "    G.write(graph_file, format='graphml')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5L0MhRZINO_",
        "outputId": "e1c03111-5337-4c9b-b886-c6e09417d84b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:07<00:00,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated memory usage: 0.00 GB\n",
            "Constructing k-NN graph...\n",
            "Performing k-NN search...\n",
            "Constructing edge list...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2298/2298 [00:00<00:00, 7985.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symmetrizing the graph...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2298/2298 [00:00<00:00, 23126.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating igraph Graph object...\n",
            "Saving graph...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Community detection**"
      ],
      "metadata": {
        "id": "rrffmIDsLRtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.utils.clustering import load_configurations\n",
        "from src.utils.parsing import parse_directories\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/NeuroScape/src')\n",
        "\n",
        "load_dotenv(\"/content/drive/MyDrive/NeuroScape/keys.env\")\n",
        "BASEPATH = os.environ['BASEPATH']\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    configurations = load_configurations()\n",
        "    directories = parse_directories()\n",
        "\n",
        "    csv_directory = os.path.join('/content/drive/MyDrive/NeuroScape/output/tratados/neuroscience')\n",
        "    graph_directory = os.path.join(\n",
        "        BASEPATH, directories['internal']['intermediate']['graphs'])\n",
        "\n",
        "    csv_file = os.path.join(csv_directory,\n",
        "                            'articles_merged_cleaned_filtered.csv')\n",
        "\n",
        "    graph_file = os.path.join(graph_directory, 'article_similarity.graphml')\n",
        "\n",
        "    print('loading graph')\n",
        "    G = ig.Graph.Read(graph_file, format='graphml')\n",
        "    pmids = G.vs['pmid']\n",
        "\n",
        "    print(\n",
        "        'running Leiden community detection for different resolution parameters'\n",
        "    )\n",
        "    num_resolution_parameter = configurations['community_detection'][\n",
        "        'num_resolution_parameter']\n",
        "    max_resolution_parameter = configurations['community_detection'][\n",
        "        'max_resolution_parameter']\n",
        "    min_resolution_parameter = max_resolution_parameter / num_resolution_parameter\n",
        "\n",
        "    resolution_parameters = np.linspace(min_resolution_parameter,\n",
        "                                        max_resolution_parameter,\n",
        "                                        num_resolution_parameter)\n",
        "\n",
        "    modularity_values = np.zeros(num_resolution_parameter)\n",
        "    num_unique_clusters = np.zeros(num_resolution_parameter)\n",
        "\n",
        "    decreasing = deque(np.zeros(5, dtype=bool))\n",
        "\n",
        "    for i, resolution_parameter in enumerate(resolution_parameters):\n",
        "        partition = leidenalg.find_partition(\n",
        "            G,\n",
        "            leidenalg.CPMVertexPartition,\n",
        "            weights='weight',\n",
        "            resolution_parameter=resolution_parameter)\n",
        "\n",
        "        modularity_values[i] = G.modularity(partition.membership,\n",
        "                                            weights='weight')\n",
        "        num_unique_clusters[i] = len(np.unique(partition.membership))\n",
        "        print(f'number of unique clusters: {num_unique_clusters[i]}')\n",
        "        print(f'modularity values: {modularity_values[i]}')\n",
        "\n",
        "        if i > 0:\n",
        "            decreasing.popleft()\n",
        "            decreasing.append(modularity_values[i] < modularity_values[i - 1])\n",
        "\n",
        "        if all(decreasing):\n",
        "            print('modularity is decreasing, breaking')\n",
        "            break\n",
        "\n",
        "    best_resolution_parameter = resolution_parameters[np.argmax(\n",
        "        modularity_values)]\n",
        "    partition = leidenalg.find_partition(\n",
        "        G,\n",
        "        leidenalg.CPMVertexPartition,\n",
        "        weights='weight',\n",
        "        resolution_parameter=best_resolution_parameter)\n",
        "\n",
        "    pmid_cluster = dict(zip(pmids, partition.membership))\n",
        "\n",
        "    print('saving cluster')\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df['Cluster ID'] = df['Pmid'].map(pmid_cluster)\n",
        "\n",
        "    new_csf_file = csv_file.replace('.csv', '_clustered.csv')\n",
        "    new_csv_file = os.path.join(csv_directory, new_csf_file)\n",
        "\n",
        "    df.to_csv(new_csv_file, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1dkrSuFLT4G",
        "outputId": "efb572f1-ba19-43e1-85b5-fbb3c8c3a7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading graph\n",
            "running Leiden community detection for different resolution parameters\n",
            "number of unique clusters: 1.0\n",
            "modularity values: 2.220446049250313e-16\n",
            "number of unique clusters: 1.0\n",
            "modularity values: 2.220446049250313e-16\n",
            "number of unique clusters: 2.0\n",
            "modularity values: 0.4383308009084261\n",
            "number of unique clusters: 2.0\n",
            "modularity values: 0.4439423512722538\n",
            "number of unique clusters: 3.0\n",
            "modularity values: 0.4709014707588849\n",
            "number of unique clusters: 3.0\n",
            "modularity values: 0.5524550631472556\n",
            "number of unique clusters: 4.0\n",
            "modularity values: 0.5995278702743098\n",
            "number of unique clusters: 5.0\n",
            "modularity values: 0.6183030926340735\n",
            "number of unique clusters: 6.0\n",
            "modularity values: 0.6607716276665074\n",
            "number of unique clusters: 6.0\n",
            "modularity values: 0.6596201635592188\n",
            "number of unique clusters: 6.0\n",
            "modularity values: 0.6641362937071349\n",
            "number of unique clusters: 7.0\n",
            "modularity values: 0.668476775516933\n",
            "number of unique clusters: 8.0\n",
            "modularity values: 0.6780492633346127\n",
            "number of unique clusters: 8.0\n",
            "modularity values: 0.682758870625542\n",
            "number of unique clusters: 8.0\n",
            "modularity values: 0.679244344680397\n",
            "number of unique clusters: 8.0\n",
            "modularity values: 0.6813481786236484\n",
            "number of unique clusters: 8.0\n",
            "modularity values: 0.6811940704687951\n",
            "number of unique clusters: 8.0\n",
            "modularity values: 0.68146895895421\n",
            "number of unique clusters: 8.0\n",
            "modularity values: 0.6805004133028889\n",
            "number of unique clusters: 10.0\n",
            "modularity values: 0.6841627534790206\n",
            "number of unique clusters: 10.0\n",
            "modularity values: 0.6839903852532206\n",
            "number of unique clusters: 10.0\n",
            "modularity values: 0.6834113200803187\n",
            "number of unique clusters: 10.0\n",
            "modularity values: 0.6839480898180865\n",
            "number of unique clusters: 11.0\n",
            "modularity values: 0.6836546414403206\n",
            "number of unique clusters: 11.0\n",
            "modularity values: 0.6835226750771777\n",
            "number of unique clusters: 10.0\n",
            "modularity values: 0.6835094168785564\n",
            "number of unique clusters: 11.0\n",
            "modularity values: 0.6835078518378145\n",
            "number of unique clusters: 12.0\n",
            "modularity values: 0.6795373913946701\n",
            "modularity is decreasing, breaking\n",
            "saving cluster\n"
          ]
        }
      ]
    }
  ]
}