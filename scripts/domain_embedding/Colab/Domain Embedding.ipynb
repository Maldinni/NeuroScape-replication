{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "IMPORTANT:\n",
        "This project is designed to run exclusively on Google Colab.\n",
        "\n",
        "It relies on Google Drive being mounted at:\n",
        "    /content/drive/MyDrive/\n",
        "\n",
        "Local execution is not supported.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "wMGoAfOp25ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MOUNTS DRIVE**"
      ],
      "metadata": {
        "id": "eklgkrYhyvTk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anZlouCYydWv",
        "outputId": "7bcb5a78-4677-467d-8900-9402ac246cb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Trabalhos/TJ/NeuroScape'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # Mounts Google Drive into the Colab environment to access project files\n",
        "\n",
        "# Changes the current working directory to the NeuroScape project folder in Google Drive\n",
        "%cd /content/drive/MyDrive/NeuroScape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTING LIBRARIES**"
      ],
      "metadata": {
        "id": "HflhXr51yzaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "from src.utils.domain_embedding import *\n",
        "from src.utils.parsing import parse_directories\n",
        "from src.utils.load_and_save import load_embedding_shards\n",
        "\n",
        "from src.classes.info_nce_loss import InfoNCELoss\n",
        "from src.classes.sparse_embedding_network import SparseEmbeddingNetwork\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv"
      ],
      "metadata": {
        "id": "xtQm1kFHy1at"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train embedding model**"
      ],
      "metadata": {
        "id": "29laDl0Yy2E8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.utils.domain_embedding import *\n",
        "from src.utils.parsing import parse_directories\n",
        "from src.utils.load_and_save import load_embedding_shards\n",
        "\n",
        "from src.classes.info_nce_loss import InfoNCELoss\n",
        "from src.classes.sparse_embedding_network import SparseEmbeddingNetwork\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/NeuroScape/src')\n",
        "\n",
        "load_dotenv(\"/content/drive/MyDrive/NeuroScape/keys.env\")\n",
        "BASEPATH = os.environ['BASEPATH']\n",
        "\n",
        "\n",
        "def train_model(model, train_data, validation_data, validation_window,\n",
        "                grokfast_ema_params, infoNCE_loss_function, correlation_weight,\n",
        "                epochs, batch_size, device, optimizer, scheduler,\n",
        "                model_save_directory):\n",
        "    \"\"\"\n",
        "    Train the model.\n",
        "\n",
        "    Parameters:\n",
        "    - model: PyTorch model, the model to train.\n",
        "    - train_data: Tensor, the training data.\n",
        "    - validation_data: Tensor, the validation data.\n",
        "    - grokfast_ema_params: Dict, the Grokfast EMA parameters.\n",
        "    - infoNCE_loss_function: InfoNCELoss, the InfoNCE loss function.\n",
        "    - correlation_weight: Float, the weight of the correlation loss.\n",
        "    - epochs: Integer, the number of epochs.\n",
        "    - batch_size: Integer, the batch size.\n",
        "    - device: PyTorch device, the device to use.\n",
        "    - optimizer: PyTorch optimizer, the optimizer to use.\n",
        "    - scheduler: PyTorch scheduler, the scheduler to use.\n",
        "    - model_save_directory: String, the path to save the model.\n",
        "    \"\"\"\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    best_loss = validate(model, validation_data, infoNCE_loss_function)\n",
        "    validation_losses = deque([best_loss] * validation_window)\n",
        "    logging = {\n",
        "        'epoch': [],\n",
        "        'training loss': [],\n",
        "        'validation loss': [],\n",
        "    }\n",
        "    current_model_file = os.path.join(model_save_directory,\n",
        "                                      'domain_embedding_model_current.pth')\n",
        "\n",
        "    logging_file = os.path.join(model_save_directory, 'logging.csv')\n",
        "\n",
        "    # Load Current Model and logging\n",
        "    if os.path.exists(current_model_file):\n",
        "        print('Continuing training from previous model')\n",
        "        model.load_state_dict(torch.load(current_model_file))\n",
        "        logging = load_log(logging_file)\n",
        "        best_loss = min(logging['validation loss'])\n",
        "    else:\n",
        "        print('Starting training from scratch')\n",
        "\n",
        "    # Initialize Gradients for EMA\n",
        "    gradients = None\n",
        "    total_samples = train_data.shape[0]\n",
        "\n",
        "    numerator = total_samples // batch_size\n",
        "    for epoch in range(epochs):\n",
        "        train_loss_average = 0\n",
        "        correlation_loss_average = 0\n",
        "\n",
        "        np.random.shuffle(train_data)\n",
        "\n",
        "        for j in range(0, total_samples, batch_size):\n",
        "            indices = range(j, min(j + batch_size, total_samples))\n",
        "            X_batch = extract_batch(train_data, indices, device)\n",
        "            train_loss, correlation_loss, gradients = train_one_batch(\n",
        "                model, X_batch, infoNCE_loss_function, correlation_weight,\n",
        "                optimizer, gradients, grokfast_ema_params)\n",
        "            train_loss_average += train_loss\n",
        "            correlation_loss_average += correlation_loss\n",
        "\n",
        "        train_loss_average /= numerator\n",
        "        correlation_loss /= numerator\n",
        "        correlation_loss /= correlation_weight\n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Validate Model\n",
        "        current_val_loss = validate(model, validation_data,\n",
        "                                    infoNCE_loss_function)\n",
        "\n",
        "        # Update Validation Loss\n",
        "        validation_losses.popleft()\n",
        "        validation_losses.append(current_val_loss)\n",
        "\n",
        "        validation_loss = sum(validation_losses) / validation_window\n",
        "\n",
        "        # Report Results\n",
        "        print(\n",
        "            f'Epoch {epoch + 1:5d}/{epochs}, Training Loss: {train_loss_average:.4f}, Validation Loss: {validation_loss:.4f}, Correlation Loss: {correlation_loss:.4f}, Time Taken: {time.time() - start:.2f}s'\n",
        "        )\n",
        "        print('---' * 10)\n",
        "\n",
        "        # Save logging\n",
        "        logging['epoch'].append(epoch + 1)\n",
        "        logging['training loss'].append(train_loss_average)\n",
        "        logging['validation loss'].append(validation_loss)\n",
        "        pd.DataFrame(logging).to_csv(logging_file, index=False)\n",
        "\n",
        "        # Save Current Model\n",
        "        save_model(model,\n",
        "                   model_save_directory,\n",
        "                   name='domain_embedding_model_current.pth')\n",
        "\n",
        "        # Reset Timer\n",
        "        start = time.time()\n",
        "\n",
        "        # Save Best Model\n",
        "        if validation_loss < best_loss:\n",
        "            best_loss = validation_loss\n",
        "            save_model(model,\n",
        "                       model_save_directory,\n",
        "                       name='domain_embedding_model_best.pth')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # Load Configurations\n",
        "    configurations = load_configurations()\n",
        "    directories = parse_directories()\n",
        "\n",
        "    data_directory = os.path.join(\n",
        "        '/content/drive/MyDrive/NeuroScape/output/filtrados')\n",
        "    model_save_directory = os.path.join(\n",
        "        BASEPATH, directories['internal']['intermediate']['models'])\n",
        "    train_data_file = os.path.join(data_directory, 'train_data.txt')\n",
        "    validation_data_file = os.path.join(data_directory, 'validation_data.txt')\n",
        "\n",
        "    device = configurations['model']['device']\n",
        "    input_dimension = configurations['model']['input_dimension']\n",
        "    hidden_dimensions = configurations['model']['hidden_dimensions']\n",
        "    output_dimension = configurations['model']['output_dimension']\n",
        "\n",
        "    epochs = configurations['training']['epochs']\n",
        "    batch_size = configurations['training']['batch_size']\n",
        "\n",
        "    initial_learning_rate = configurations['training']['initial_learning_rate']\n",
        "    minimum_learning_rate = configurations['training']['minimum_learning_rate']\n",
        "    gamma = (minimum_learning_rate / initial_learning_rate)**(1 / epochs)\n",
        "    validation_window = configurations['training']['validation_window']\n",
        "    validation_size = configurations['training']['validation_size']\n",
        "\n",
        "    grokfast_ema_params = configurations['grokfast_ema']\n",
        "\n",
        "    dropout = configurations['regularization']['dropout']\n",
        "    l2_weight = configurations['regularization']['l2_weight']\n",
        "    correlation_weight = configurations['regularization']['correlation_weight']\n",
        "\n",
        "    info_nce_temperature = configurations['InfoNCE']['temperature']\n",
        "    cutoff_values = configurations['InfoNCE']['cutoff_values']\n",
        "\n",
        "    # Define Model\n",
        "    embedding_network = SparseEmbeddingNetwork(\n",
        "        input_dimension=input_dimension,\n",
        "        hidden_dimensions=hidden_dimensions,\n",
        "        output_dimension=output_dimension,\n",
        "        dropout=dropout).to(device)\n",
        "\n",
        "    # Define Loss\n",
        "    infoNCE_loss_function = InfoNCELoss(temperature=info_nce_temperature,\n",
        "                                        cutoff_values=cutoff_values)\n",
        "\n",
        "    # Get Optimizer and Scheduler\n",
        "    optimizer, scheduler = setup_optimizer_scheduler(embedding_network,\n",
        "                                                     initial_learning_rate,\n",
        "                                                     gamma, l2_weight)\n",
        "\n",
        "    # Get Data\n",
        "    if os.path.exists(train_data_file):\n",
        "        print('Loading training and validation data from files')\n",
        "        with open(train_data_file, 'r') as f:\n",
        "            train_files = f.read().splitlines()\n",
        "        with open(validation_data_file, 'r') as f:\n",
        "            validation_files = f.read().splitlines()\n",
        "\n",
        "    else:\n",
        "        print('Splitting data into training and validation sets')\n",
        "        train_files, validation_files = get_and_split_files(\n",
        "            data_directory, validation_size)\n",
        "\n",
        "        print(\n",
        "            f'\\tTraining Files: {len(train_files)}, Validation Files: {len(validation_files)}'\n",
        "        )\n",
        "\n",
        "        with open(train_data_file, 'w') as f:\n",
        "            f.write('\\n'.join(train_files))\n",
        "        with open(validation_data_file, 'w') as f:\n",
        "            f.write('\\n'.join(validation_files))\n",
        "\n",
        "    validation_data, _ = load_embedding_shards(validation_files)\n",
        "    validation_data = torch.tensor(validation_data,\n",
        "                                   dtype=torch.float32).to(device)\n",
        "\n",
        "    training_data, _ = load_embedding_shards(train_files)\n",
        "\n",
        "    # Train Model\n",
        "    train_model(embedding_network, training_data, validation_data,\n",
        "                validation_window, grokfast_ema_params, infoNCE_loss_function,\n",
        "                correlation_weight, epochs, batch_size, device, optimizer,\n",
        "                scheduler, model_save_directory)\n",
        "\n",
        "    # Save Final Model\n",
        "    save_model(embedding_network,\n",
        "               model_save_directory,\n",
        "               name='domain_embedding_model_final.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "yB4uxOgIy5mb",
        "outputId": "4c4c40e1-9d30-4e1d-e38a-fd078ee0038d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'BASEPATH'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1912573702.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mload_dotenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Trabalhos/TJ/NeuroScape/keys.env\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mBASEPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BASEPATH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'BASEPATH'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Embbeded_abstracts**"
      ],
      "metadata": {
        "id": "JozhthQ2-jqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "\n",
        "from src.utils.parsing import parse_directories\n",
        "from src.classes.sparse_embedding_network import SparseEmbeddingNetwork\n",
        "from src.utils.domain_embedding import load_configurations, perform_domain_embedding\n",
        "from src.utils.load_and_save import load_articles_from_hdf5, save_articles_to_hdf5\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/NeuroScape/src')\n",
        "\n",
        "load_dotenv(\"/content/drive/MyDrive/NeuroScape/keys.env\")\n",
        "BASEPATH = os.environ['BASEPATH']\n",
        "\n",
        "\n",
        "def load_embedding_network(input_dimension, hidden_dimensions,\n",
        "                           output_dimension, device, model_file):\n",
        "    \"\"\"\n",
        "    Load the embedding network.\n",
        "\n",
        "    Parameters:\n",
        "    - input_dimension: int, the input dimension.\n",
        "    - hidden_dimensions: list, the hidden dimensions.\n",
        "    - output_dimension: int, the output dimension.\n",
        "    - dropout: float, the dropout rate.\n",
        "    - device: str, the device to use.\n",
        "    - model_file: str, the path to the model file.\n",
        "\n",
        "    Returns:\n",
        "    - embedding_network: SparseEmbeddingNetwork, the embedding network.\n",
        "    \"\"\"\n",
        "\n",
        "    embedding_network = SparseEmbeddingNetwork(\n",
        "        input_dimension=input_dimension,\n",
        "        hidden_dimensions=hidden_dimensions,\n",
        "        output_dimension=output_dimension).to(device)\n",
        "\n",
        "    embedding_network.load_state_dict(torch.load(model_file))\n",
        "    embedding_network.eval()\n",
        "    return embedding_network\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load Configurations\n",
        "    configurations = load_configurations()\n",
        "\n",
        "    device = configurations['model']['device']\n",
        "    input_dimension = configurations['model']['input_dimension']\n",
        "    hidden_dimensions = configurations['model']['hidden_dimensions']\n",
        "    output_dimension = configurations['model']['output_dimension']\n",
        "\n",
        "    directories = parse_directories()\n",
        "\n",
        "    original_data_directory = os.path.join(\n",
        "        '/content/drive/MyDrive/NeuroScape/output/filtrados')\n",
        "    new_data_directory = os.path.join(\n",
        "        BASEPATH, directories['internal']['intermediate']['hdf5']['neuro'])\n",
        "    model_save_directory = os.path.join(\n",
        "        BASEPATH, directories['internal']['intermediate']['models'])\n",
        "\n",
        "    os.makedirs(new_data_directory, exist_ok=True)\n",
        "\n",
        "    model_file = os.path.join(model_save_directory,\n",
        "                              'domain_embedding_model_best.pth')\n",
        "\n",
        "    embedding_network = load_embedding_network(input_dimension,\n",
        "                                               hidden_dimensions,\n",
        "                                               output_dimension, device,\n",
        "                                               model_file)\n",
        "\n",
        "    article_files = glob(os.path.join(original_data_directory, '*.h5'))\n",
        "    print(f'Found {len(article_files)} article files.')\n",
        "    for article_file in tqdm(article_files):\n",
        "        articles = load_articles_from_hdf5(article_file, disable_tqdm=True)\n",
        "        for article in articles:\n",
        "            embedding = np.array(article.embedding).reshape(1, -1)\n",
        "\n",
        "            article.embedding = perform_domain_embedding(\n",
        "                embedding_network, embedding, device).squeeze(axis=0).tolist()\n",
        "\n",
        "        new_filename = os.path.join(new_data_directory,\n",
        "                                    os.path.basename(article_file))\n",
        "        save_articles_to_hdf5(articles, new_filename, disable_tqdm=True)\n",
        "\n",
        "    print('Done.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "42om3mK--Gxt",
        "outputId": "f503400d-5ada-433e-a005-6caebec7f220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Trabalhos/TJ/NeuroScape/data/Internal/Intermediate/Models/domain_embedding_model_best.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1136738590.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m                               'domain_embedding_model_best.pth')\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     embedding_network = load_embedding_network(input_dimension,\n\u001b[0m\u001b[1;32m     66\u001b[0m                                                \u001b[0mhidden_dimensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                                                \u001b[0moutput_dimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1136738590.py\u001b[0m in \u001b[0;36mload_embedding_network\u001b[0;34m(input_dimension, hidden_dimensions, output_dimension, device, model_file)\u001b[0m\n\u001b[1;32m     35\u001b[0m         output_dimension=output_dimension).to(device)\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0membedding_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0membedding_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0membedding_network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFileLike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Trabalhos/TJ/NeuroScape/data/Internal/Intermediate/Models/domain_embedding_model_best.pth'"
          ]
        }
      ]
    }
  ]
}