{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "IMPORTANT:\n",
        "This project is designed to run exclusively on Google Colab.\n",
        "\n",
        "It relies on Google Drive being mounted at:\n",
        "    /content/drive/MyDrive/\n",
        "\n",
        "Local execution is not supported.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "4nXfW1XzMalT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INSTALLING LIBRARIES**"
      ],
      "metadata": {
        "id": "q3BqH44hUJmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install igraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaGhdqFqlbCo",
        "outputId": "d276c698-398b-4835-ce9b-66272c968a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting igraph\n",
            "  Downloading igraph-0.11.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting texttable>=1.6.2 (from igraph)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Downloading igraph-0.11.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable, igraph\n",
            "Successfully installed igraph-0.11.9 texttable-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MOUNTS DRIVE**"
      ],
      "metadata": {
        "id": "-BFNVV4CUGVB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aaxv6aMjiD1k",
        "outputId": "2db077bb-563e-4328-b5dd-559a81098115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1vM2NZYPQBx0CCXgmkPKl1lguMSLh85MO/NeuroScape\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)  # Mounts Google Drive into the Colab environment to access project files\n",
        "\n",
        "# Changes the current working directory to the NeuroScape project folder in Google Drive\n",
        "%cd /content/drive/MyDrive/NeuroScape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTING LIBRARIES**"
      ],
      "metadata": {
        "id": "u6p8n0stUOAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import igraph as ig"
      ],
      "metadata": {
        "id": "m2_I6T3aUNy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cluster Density**"
      ],
      "metadata": {
        "id": "Rb1U_Wc0iQEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from src.utils.cluster_graph import *\n",
        "from src.utils.parsing import parse_directories\n",
        "from src.utils.load_and_save import load_articles_from_hdf5\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "# Add the 'src' directory to the system path\n",
        "# This allows importing project-specific modules\n",
        "sys.path.append('/content/drive/MyDrive/NeuroScape/src')\n",
        "\n",
        "# Load environment variables from the .env file\n",
        "load_dotenv(find_dotenv())\n",
        "BASEPATH = os.environ['BASEPATH']\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    configurations = load_configurations()\n",
        "    directories = parse_directories()\n",
        "\n",
        "    print('Loading csv files...')\n",
        "\n",
        "    csv_directory = os.path.join('/content/drive/MyDrive/NeuroScape/output/tratados/neuroscience')\n",
        "\n",
        "    article_csv_file = os.path.join(\n",
        "        csv_directory, 'articles_with_citation_rate.csv')\n",
        "\n",
        "    cluster_csv_file = os.path.join(\n",
        "        csv_directory,\n",
        "        'clusters_defined_distinguished_questions_trends_assessed.csv')\n",
        "\n",
        "    graph_directory = os.path.join(\n",
        "        BASEPATH, directories['internal']['intermediate']['graphs'])\n",
        "    graph_file = os.path.join(graph_directory, 'citation_density.graphml')\n",
        "    article_df = pd.read_csv(article_csv_file)\n",
        "    cluster_df = pd.read_csv(cluster_csv_file)\n",
        "\n",
        "    print('Loading articles...')\n",
        "    shard_directory = os.path.join(\n",
        "        BASEPATH, directories['internal']['intermediate']['hdf5']['neuro'])\n",
        "    article_files = glob(os.path.join(shard_directory, '*.h5'))\n",
        "\n",
        "    article_graph = {\n",
        "        'Pmid': [],\n",
        "        'Cluster ID': [],\n",
        "        'Year': [],\n",
        "        'Age': [],\n",
        "        'In_links': [],\n",
        "        'Out_links': []\n",
        "    }\n",
        "\n",
        "    for file in tqdm(article_files):\n",
        "        articles = load_articles_from_hdf5(file, disable_tqdm=True)\n",
        "        for article in articles:\n",
        "            article_graph['Pmid'].append(article.pmid)\n",
        "            article_graph['Cluster ID'].append(\n",
        "                article_df.loc[article_df['Pmid'] == article.pmid,\n",
        "                               'Cluster ID'].values[0])\n",
        "            article_graph['Year'].append(article.year)\n",
        "            article_graph['Age'].append(article.age)\n",
        "            article_graph['In_links'].append(article.in_links)\n",
        "            article_graph['Out_links'].append(article.out_links)\n",
        "\n",
        "    article_graph_df = pd.DataFrame(article_graph)\n",
        "\n",
        "    cluster_df['Reference Krackhardt'] = 0.0\n",
        "    cluster_df['Citation Krackhardt'] = 0.0\n",
        "    cluster_df['Most Cited Cluster'] = ''\n",
        "    cluster_df['Most Citing Cluster'] = ''\n",
        "\n",
        "    edge_list = []\n",
        "    weights_list = []\n",
        "\n",
        "    print('Performing density analyses...')\n",
        "    for source_cluster in tqdm(cluster_df['Cluster ID']):\n",
        "        krackhardt, frequent_clusters = node_analysis(article_graph_df,\n",
        "                                                      source_cluster)\n",
        "        cluster_df.loc[cluster_df['Cluster ID'] == source_cluster,\n",
        "                       'Reference Krackhardt'] = krackhardt['References']\n",
        "        cluster_df.loc[cluster_df['Cluster ID'] == source_cluster,\n",
        "                       'Citation Krackhardt'] = krackhardt['Citations']\n",
        "        cluster_df.loc[cluster_df['Cluster ID'] == source_cluster,\n",
        "                       'Most Cited Cluster'] = frequent_clusters['References']\n",
        "        cluster_df.loc[cluster_df['Cluster ID'] == source_cluster,\n",
        "                       'Most Citing Cluster'] = frequent_clusters['Citations']\n",
        "\n",
        "        for destination_cluster in cluster_df['Cluster ID']:\n",
        "            edge = tuple([source_cluster, destination_cluster])\n",
        "            edge_list.append(edge)\n",
        "            weight = edge_analysis(article_graph_df, edge)\n",
        "            weights_list.append(weight)\n",
        "\n",
        "    # Most Cited Cluster and Most Citing Cluster before Most Similar Cluster\n",
        "    columns = cluster_df.columns.tolist()\n",
        "    columns = columns[:6] + columns[-4:] + columns[6:-4]\n",
        "    cluster_df = cluster_df[columns]\n",
        "\n",
        "    print('Saving csv file...')\n",
        "    cluster_csv_file = cluster_csv_file.replace('.csv', '_density.csv')\n",
        "    cluster_df.to_csv(cluster_csv_file, index=False)\n",
        "\n",
        "    print('Creating igraph Graph object')\n",
        "    reference_density_graph = ig.Graph(edges=edge_list, directed=True)\n",
        "    reference_density_graph.es['weight'] = weights_list\n",
        "    reference_density_graph.vs['label'] = cluster_df['Cluster ID']\n",
        "\n",
        "    print('Saving graphs...')\n",
        "    reference_density_graph.save(graph_file, format='graphml')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nde3GU-XiWtu",
        "outputId": "1242fcd0-94ca-4ae3-ca99-742f3c440eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading csv files...\n",
            "Loading articles...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:07<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing density analyses...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:29<00:00,  3.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving csv file...\n",
            "Creating igraph Graph object\n",
            "Saving graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}